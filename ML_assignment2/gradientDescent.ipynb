{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch dataset \n",
    "#wine_quality = fetch_ucirepo(id=186) \n",
    "   \n",
    "#X = wine_quality.data.features \n",
    "#y = wine_quality.data.targets \n",
    "  \n",
    "#print(wine_quality.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0               7.4              0.70         0.00             1.9      0.076   \n",
      "1               7.8              0.88         0.00             2.6      0.098   \n",
      "2               7.8              0.76         0.04             2.3      0.092   \n",
      "3              11.2              0.28         0.56             1.9      0.075   \n",
      "4               7.4              0.70         0.00             1.9      0.076   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "4893            6.2              0.21         0.29             1.6      0.039   \n",
      "4894            6.6              0.32         0.36             8.0      0.047   \n",
      "4895            6.5              0.24         0.19             1.2      0.041   \n",
      "4896            5.5              0.29         0.30             1.1      0.022   \n",
      "4897            6.0              0.21         0.38             0.8      0.020   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
      "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
      "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
      "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
      "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
      "\n",
      "      alcohol  quality  \n",
      "0         9.4        5  \n",
      "1         9.8        5  \n",
      "2         9.8        5  \n",
      "3         9.8        6  \n",
      "4         9.4        5  \n",
      "...       ...      ...  \n",
      "4893     11.2        6  \n",
      "4894      9.6        5  \n",
      "4895      9.4        6  \n",
      "4896     12.8        7  \n",
      "4897     11.8        6  \n",
      "\n",
      "[6497 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "red_wine_df = pd.read_csv(\"winequality-red.csv\", delimiter=\";\")\n",
    "white_wine_df = pd.read_csv(\"winequality-white.csv\", delimiter=\";\")\n",
    "\n",
    "wine_df = pd.concat([red_wine_df, white_wine_df], axis=0)\n",
    "\n",
    "X = wine_df.drop(columns=['quality'])\n",
    "y = wine_df['quality']\n",
    "\n",
    "print(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Converting data to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Cost: 178718.70830576826\n",
      "Final weights with a1 = 0.001: [ 5.81450837  0.10170125 -0.21905526 -0.02080019  0.22033506 -0.01159569\n",
      "  0.12250196 -0.14950612 -0.17726483  0.07704958  0.12015313  0.32246666]\n",
      "Final weights with a2 = 0.01: [ 5.81450837  0.10170125 -0.21905526 -0.02080019  0.22033506 -0.01159569\n",
      "  0.12250196 -0.14950612 -0.17726483  0.07704958  0.12015313  0.32246666]\n",
      "Final weights with a3 = 0.1: [ 5.81450837  0.10170125 -0.21905526 -0.02080019  0.22033506 -0.01159569\n",
      "  0.12250196 -0.14950612 -0.17726483  0.07704958  0.12015313  0.32246666]\n"
     ]
    }
   ],
   "source": [
    "# Function for calculating residual sum of squares\n",
    "def residual_sum_of_squares(y_real, y_pred):\n",
    "    RSS = np.sum((y_real - y_pred) ** 2)\n",
    "    return RSS\n",
    "\n",
    "# Function for calculating gradient of residual sum of squares\n",
    "def compute_gradient(X, y_real, y_pred):\n",
    "    m = len(y_real)\n",
    "    error = y_real - y_pred\n",
    "    transposed_X = X.transpose()\n",
    "    gradient = -2 * transposed_X.dot(error) / m\n",
    "\n",
    "    return gradient\n",
    "\n",
    "# Initialize parameters\n",
    "a1 = 0.001  # Learning rate 1\n",
    "a2 = 0.01 # Learning rate 2\n",
    "a3 = 0.1 # Learning rate 3\n",
    "number_of_iterations = 10000  # Number of iterations\n",
    "num_row = X_train.shape[0]\n",
    "num_col = X_train.shape[1]\n",
    "\n",
    "X_train = np.c_[np.ones(num_row), X_train] # Add bias term to X_train (vector of ones is concataneted to X_train from the left)\n",
    "w = np.random.randn(num_col + 1) * 0.01 # Initialize weights randomly but mutiply with 0.01 to get smaller values\n",
    "w1 = w2 = w3 = w\n",
    "\n",
    "# Gradient descent algorithm\n",
    "for i in range(number_of_iterations):\n",
    "    \n",
    "    y_pred_train_1 = X_train.dot(w1)\n",
    "    y_pred_train_2 = X_train.dot(w2)\n",
    "    y_pred_train_3 = X_train.dot(w3)\n",
    "\n",
    "    RSS_1 = residual_sum_of_squares(y_train, y_pred_train_1) # Calculate RSS for w1\n",
    "    \n",
    "    RSS_gradient_1 = compute_gradient(X_train, y_train, y_pred_train_1)\n",
    "    RSS_gradient_2 = compute_gradient(X_train, y_train, y_pred_train_2)\n",
    "    RSS_gradient_3 = compute_gradient(X_train, y_train, y_pred_train_3)\n",
    "\n",
    "    \n",
    "    w1 -= a1 * RSS_gradient_1 # Update weights w1\n",
    "    w2 -= a2 * RSS_gradient_2 # Update weights w2\n",
    "    w3 -= a3 * RSS_gradient_3 # Update weights w3\n",
    "\n",
    "\n",
    "    # Print cost every 1000 iterations\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Iteration {i}, Cost: {RSS_1}\")\n",
    "\n",
    "print(f\"Final weights with a1 = 0.001: {w1}\")\n",
    "print(f\"Final weights with a2 = 0.01: {w2}\")\n",
    "print(f\"Final weights with a3 = 0.1: {w3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling X_test with scaler fitted to X_train\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Converting to numpy arrays\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Adding bias term to X_test\n",
    "num_row = X_test.shape[0]\n",
    "X_test = np.c_[np.ones(num_row), X_test]\n",
    "\n",
    "# Making predictions for X_test\n",
    "y_pred_test_1 = X_test.dot(w1)\n",
    "y_pred_test_2 = X_test.dot(w2)\n",
    "y_pred_test_3 = X_test.dot(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): [0.5658710072506614, 0.5658710072506614, 0.5658710072506614]\n",
      "Mean Squared Error (MSE): [0.5466958511495601, 0.5466958511495601, 0.5466958511495601]\n",
      "Root Mean Squared Error (RMSE): [0.73938884 0.73938884 0.73938884]\n",
      "R-squared: [0.2597681129398879, 0.2597681129398879, 0.2597681129398879]\n"
     ]
    }
   ],
   "source": [
    "# Measures of performance\n",
    "mae = [ mean_absolute_error(y_test, y_pred_test_1), mean_absolute_error(y_test, y_pred_test_2), mean_absolute_error(y_test, y_pred_test_3)] \n",
    "mse = [ mean_squared_error(y_test, y_pred_test_1), mean_squared_error(y_test, y_pred_test_2), mean_squared_error(y_test, y_pred_test_3)]\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = [r2_score(y_test, y_pred_test_1), r2_score(y_test, y_pred_test_2), r2_score(y_test, y_pred_test_3)]\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.568514098413171\n",
      "Mean Squared Error (MSE): 0.5541035332628875\n",
      "Root Mean Squared Error (RMSE): 0.74438130904993\n",
      "R-squared: 0.2497380340615507\n"
     ]
    }
   ],
   "source": [
    "# Using the implemented gradient descent algorithm from sklearn library\n",
    "sgd_regressor = SGDRegressor(max_iter=10000, tol=1e-3, learning_rate='constant', eta0=0.001, random_state=42)\n",
    "sgd_regressor.fit(X_train, y_train)\n",
    "y_pred_test_sklearn = sgd_regressor.predict(X_test)\n",
    "\n",
    "# Metrics of performance\n",
    "mae = mean_absolute_error(y_test, y_pred_test_sklearn)\n",
    "mse = mean_squared_error(y_test, y_pred_test_sklearn)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_test_sklearn)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.43814615384615385\n",
      "Mean Squared Error (MSE): 0.3696033076923077\n",
      "Root Mean Squared Error (RMSE): 0.6079500865139404\n",
      "R-squared: 0.4995532646874079\n"
     ]
    }
   ],
   "source": [
    "# Random Forest regression\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred_test_rf = rf_regressor.predict(X_test)\n",
    "\n",
    "# Metrics of performance\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_test_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_test_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_test_rf)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae_rf}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_rf}\")\n",
    "print(f\"R-squared: {r2_rf}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
